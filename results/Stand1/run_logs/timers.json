{
    "name": "root",
    "gauges": {
        "Stand.Policy.Entropy.mean": {
            "value": 0.9175437092781067,
            "min": 0.9175437092781067,
            "max": 1.298523187637329,
            "count": 91
        },
        "Stand.Policy.Entropy.sum": {
            "value": 27526.310546875,
            "min": 6752.32080078125,
            "max": 38931.81640625,
            "count": 91
        },
        "Stand.Environment.EpisodeLength.mean": {
            "value": 9.570320761367642,
            "min": 8.028588624736683,
            "max": 9.570320761367642,
            "count": 91
        },
        "Stand.Environment.EpisodeLength.sum": {
            "value": 27151.0,
            "min": 4603.0,
            "max": 27163.0,
            "count": 91
        },
        "Stand.Step.mean": {
            "value": 4199989.0,
            "min": 1499995.0,
            "max": 4199989.0,
            "count": 91
        },
        "Stand.Step.sum": {
            "value": 4199989.0,
            "min": 1499995.0,
            "max": 4199989.0,
            "count": 91
        },
        "Stand.Policy.ExtrinsicValueEstimate.mean": {
            "value": -6.295097827911377,
            "min": -9.04333782196045,
            "max": -6.239560604095459,
            "count": 91
        },
        "Stand.Policy.ExtrinsicValueEstimate.sum": {
            "value": -17865.48828125,
            "min": -29975.861328125,
            "max": -5090.01416015625,
            "count": 91
        },
        "Stand.Environment.CumulativeReward.mean": {
            "value": -4.151343428307306,
            "min": -9.590927647278372,
            "max": -4.140450570598465,
            "count": 91
        },
        "Stand.Environment.CumulativeReward.sum": {
            "value": -11781.512649536133,
            "min": -31036.93906867504,
            "max": -5418.87412071228,
            "count": 91
        },
        "Stand.Policy.ExtrinsicReward.mean": {
            "value": -4.151343428307306,
            "min": -9.590927647278372,
            "max": -4.140450570598465,
            "count": 91
        },
        "Stand.Policy.ExtrinsicReward.sum": {
            "value": -11781.512649536133,
            "min": -31036.93906867504,
            "max": -5418.87412071228,
            "count": 91
        },
        "Stand.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 91
        },
        "Stand.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 91
        },
        "Stand.Losses.PolicyLoss.mean": {
            "value": 0.018083338076685322,
            "min": 0.014660368638287765,
            "max": 0.023593131478410214,
            "count": 90
        },
        "Stand.Losses.PolicyLoss.sum": {
            "value": 0.036166676153370644,
            "min": 0.014660368638287765,
            "max": 0.042768171983771024,
            "count": 90
        },
        "Stand.Losses.ValueLoss.mean": {
            "value": 6.452394666671752,
            "min": 6.335020704269409,
            "max": 14.586684169769287,
            "count": 90
        },
        "Stand.Losses.ValueLoss.sum": {
            "value": 12.904789333343505,
            "min": 6.474924087524414,
            "max": 26.337413902282716,
            "count": 90
        },
        "Stand.Policy.LearningRate.mean": {
            "value": 0.0004301868222959716,
            "min": 0.0004301868222959716,
            "max": 0.0004747446383844067,
            "count": 90
        },
        "Stand.Policy.LearningRate.sum": {
            "value": 0.0008603736445919432,
            "min": 0.00043069903052686325,
            "max": 0.0009484648769736932,
            "count": 90
        },
        "Stand.Policy.Epsilon.mean": {
            "value": 0.1860373616666667,
            "min": 0.1860373616666667,
            "max": 0.1949489266666667,
            "count": 90
        },
        "Stand.Policy.Epsilon.sum": {
            "value": 0.3720747233333334,
            "min": 0.18613980333333335,
            "max": 0.38969297333333336,
            "count": 90
        },
        "Stand.Policy.Beta.mean": {
            "value": 0.004303264347166666,
            "min": 0.004303264347166666,
            "max": 0.004747951440666667,
            "count": 90
        },
        "Stand.Policy.Beta.sum": {
            "value": 0.008606528694333333,
            "min": 0.004308376186333333,
            "max": 0.009485679369333333,
            "count": 90
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1732308855",
        "python_version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "c:\\Users\\eriol\\Desktop\\Unity\\DynamicRagdoll\\venv\\Scripts\\mlagents-learn Config\\ppo\\Stand.yaml --run-id=Stand1 --resume",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.1+cu124",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1732317331"
    },
    "total": 8475.99759460002,
    "count": 1,
    "self": 0.007112099992809817,
    "children": {
        "run_training.setup": {
            "total": 0.12913290000869893,
            "count": 1,
            "self": 0.12913290000869893
        },
        "TrainerController.start_learning": {
            "total": 8475.861349600018,
            "count": 1,
            "self": 11.159186305420008,
            "children": {
                "TrainerController._reset_env": {
                    "total": 46.4697046999936,
                    "count": 1,
                    "self": 46.4697046999936
                },
                "TrainerController.advance": {
                    "total": 8418.048617394612,
                    "count": 549430,
                    "self": 9.18075109901838,
                    "children": {
                        "env_step": {
                            "total": 6187.119561401283,
                            "count": 549430,
                            "self": 4883.278554482997,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1297.1349598189117,
                                    "count": 549430,
                                    "self": 22.711668725474738,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1274.423291093437,
                                            "count": 338417,
                                            "self": 1274.423291093437
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 6.7060470993747,
                                    "count": 549429,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 8415.835072798829,
                                            "count": 549429,
                                            "is_parallel": true,
                                            "self": 4063.7380332980247,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.001725899986922741,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00011470000026747584,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.001611199986655265,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.001611199986655265
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 4352.0953136008175,
                                                    "count": 549429,
                                                    "is_parallel": true,
                                                    "self": 104.21155118278693,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 91.13375411424204,
                                                            "count": 549429,
                                                            "is_parallel": true,
                                                            "self": 91.13375411424204
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3871.7604418029077,
                                                            "count": 549429,
                                                            "is_parallel": true,
                                                            "self": 3871.7604418029077
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 284.98956650088076,
                                                            "count": 549429,
                                                            "is_parallel": true,
                                                            "self": 40.0640134071873,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 244.92555309369345,
                                                                    "count": 1098858,
                                                                    "is_parallel": true,
                                                                    "self": 244.92555309369345
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 2221.7483048943104,
                            "count": 549429,
                            "self": 11.648731192108244,
                            "children": {
                                "process_trajectory": {
                                    "total": 1677.6023697022756,
                                    "count": 549429,
                                    "self": 1676.853866602236,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.7485031000396702,
                                            "count": 6,
                                            "self": 0.7485031000396702
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 532.4972039999266,
                                    "count": 132,
                                    "self": 345.60646899964195,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 186.89073500028462,
                                            "count": 6600,
                                            "self": 186.89073500028462
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 9.00006853044033e-07,
                    "count": 1,
                    "self": 9.00006853044033e-07
                },
                "TrainerController._save_models": {
                    "total": 0.18384029998560436,
                    "count": 1,
                    "self": 0.012462499988032505,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.17137779999757186,
                            "count": 1,
                            "self": 0.17137779999757186
                        }
                    }
                }
            }
        }
    }
}